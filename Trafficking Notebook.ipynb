{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Machine Learning with Spark ML\n",
    "\n",
    "### In this notebook, we will explore machine learning using Spark ML. We will exploit Spark ML's high-level APIs built on top of DataFrames to create and tune machine learning pipelines. Spark ML Pipelines enable combining multiple algorithms into a single pipeline or workflow. We will utilize Spark ML's feature transformers to convert, modify and scale the features that will be used to develop the machine learning model. Finally, we will evaluate and cross validate our model to demonstrate the process of determining a best fit model and load the results in the database.\n",
    "\n",
    "### We are using machine learning to try to predict records that a human has not seen or vetted before. We will use these predictions to sort the highest priority records for a human to look at. We will use as a training set for the algorithm fake data that has been vetted by an analyst as high, medium or low.Â¶\n",
    "\n",
    "### We will use generated travel data that has been examined for patterns of Human Trafficking from a DB2 table to do the machine learning.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "\n",
    "1. [Create Version](#version)\n",
    "1. [Import Libraries](#install)\n",
    "1. [Read from Object Storage](#object)\n",
    "1. [Transform the data](#transform)\n",
    "1. [Feature Engineering](#engineering)\n",
    "1. [Model the data](#model)\n",
    "1. [Setup the Pipeline](#pipeline)\n",
    "1. [Train the model](#train)\n",
    "1. [Evaluate results](#evaluate)\n",
    "1. [Hyperparameter Tuning](#tuning)\n",
    "1. [Score the records](#score)\n",
    "1. [Insert Credentials](#credentials)\n",
    "1. [Write Results](#write)\n",
    "1. [Create New Version](#version2)\n",
    "1. [Schedule Job](#schedule)\n",
    "1. [Revert to Version](#revert)\n",
    "1. [Even More Help](#help)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"version\"></a>\n",
    "## Create Version \n",
    "\n",
    "Save a version of the notebook by selecting <b>File</b> > <b>Save Version</b> \n",
    "<img alt=\"IBM Bluemix.Get started now\" src=\"https://raw.githubusercontent.com/jpatter/LMCO/master/Lab-1/images/FileOptions.PNG\" > or by selecting the <b>Versions</b> icon and selecting <b>Save Version</b>. <img alt=\"IBM Bluemix.Get started now\" src=\"https://raw.githubusercontent.com/jpatter/LMCO/master/Lab-1/images/versions-button.png\" ><br>\n",
    "You can have up to ten (10) versions of a notebook.   Notebook versions are saved in a FIFO manner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upgrade Watson Machine Learning Client library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting watson-machine-learning-client-V4\n",
      "  Using cached https://files.pythonhosted.org/packages/5b/85/d1ae875e6a2247bf40f1da183dca698415e6fa42fa002a4d8ef7142df0cf/watson_machine_learning_client_V4-1.0.60-py3-none-any.whl\n",
      "Collecting tqdm (from watson-machine-learning-client-V4)\n",
      "  Using cached https://files.pythonhosted.org/packages/cd/80/5bb262050dd2f30f8819626b7c92339708fe2ed7bd5554c8193b4487b367/tqdm-4.42.1-py2.py3-none-any.whl\n",
      "Collecting urllib3 (from watson-machine-learning-client-V4)\n",
      "  Using cached https://files.pythonhosted.org/packages/e8/74/6e4f91745020f967d09332bb2b8b9b10090957334692eb88ea4afe91b77f/urllib3-1.25.8-py2.py3-none-any.whl\n",
      "Collecting certifi (from watson-machine-learning-client-V4)\n",
      "  Using cached https://files.pythonhosted.org/packages/b9/63/df50cac98ea0d5b006c55a399c3bf1db9da7b5a24de7890bc9cfd5dd9e99/certifi-2019.11.28-py2.py3-none-any.whl\n",
      "Collecting requests (from watson-machine-learning-client-V4)\n",
      "  Using cached https://files.pythonhosted.org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/requests-2.22.0-py2.py3-none-any.whl\n",
      "Collecting tabulate (from watson-machine-learning-client-V4)\n",
      "Collecting pandas (from watson-machine-learning-client-V4)\n",
      "  Using cached https://files.pythonhosted.org/packages/12/d1/a6502c2f5c15b50f5dd579fc1c52b47edf6f2e9f682aed917dd7565b3e60/pandas-1.0.0-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting lomond (from watson-machine-learning-client-V4)\n",
      "  Using cached https://files.pythonhosted.org/packages/0f/b1/02eebed49c754b01b17de7705caa8c4ceecfb4f926cdafc220c863584360/lomond-0.3.3-py2.py3-none-any.whl\n",
      "Collecting ibm-cos-sdk (from watson-machine-learning-client-V4)\n",
      "Collecting idna<2.9,>=2.5 (from requests->watson-machine-learning-client-V4)\n",
      "  Using cached https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl\n",
      "Collecting chardet<3.1.0,>=3.0.2 (from requests->watson-machine-learning-client-V4)\n",
      "  Using cached https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl\n",
      "Collecting python-dateutil>=2.6.1 (from pandas->watson-machine-learning-client-V4)\n",
      "  Using cached https://files.pythonhosted.org/packages/d4/70/d60450c3dd48ef87586924207ae8907090de0b306af2bce5d134d78615cb/python_dateutil-2.8.1-py2.py3-none-any.whl\n",
      "Collecting numpy>=1.13.3 (from pandas->watson-machine-learning-client-V4)\n",
      "  Using cached https://files.pythonhosted.org/packages/62/20/4d43e141b5bc426ba38274933ef8e76e85c7adea2c321ecf9ebf7421cedf/numpy-1.18.1-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting pytz>=2017.2 (from pandas->watson-machine-learning-client-V4)\n",
      "  Using cached https://files.pythonhosted.org/packages/e7/f9/f0b53f88060247251bf481fa6ea62cd0d25bf1b11a87888e53ce5b7c8ad2/pytz-2019.3-py2.py3-none-any.whl\n",
      "Collecting six>=1.10.0 (from lomond->watson-machine-learning-client-V4)\n",
      "  Using cached https://files.pythonhosted.org/packages/65/eb/1f97cb97bfc2390a276969c6fae16075da282f5058082d4cb10c6c5c1dba/six-1.14.0-py2.py3-none-any.whl\n",
      "Collecting ibm-cos-sdk-core==2.6.0 (from ibm-cos-sdk->watson-machine-learning-client-V4)\n",
      "Collecting ibm-cos-sdk-s3transfer==2.6.0 (from ibm-cos-sdk->watson-machine-learning-client-V4)\n",
      "Collecting jmespath<1.0.0,>=0.7.1 (from ibm-cos-sdk->watson-machine-learning-client-V4)\n",
      "  Using cached https://files.pythonhosted.org/packages/83/94/7179c3832a6d45b266ddb2aac329e101367fbdb11f425f13771d27f225bb/jmespath-0.9.4-py2.py3-none-any.whl\n",
      "Collecting docutils<0.16,>=0.10 (from ibm-cos-sdk-core==2.6.0->ibm-cos-sdk->watson-machine-learning-client-V4)\n",
      "  Using cached https://files.pythonhosted.org/packages/22/cd/a6aa959dca619918ccb55023b4cb151949c64d4d5d55b3f4ffd7eee0c6e8/docutils-0.15.2-py3-none-any.whl\n",
      "\u001b[31mtensorflow 1.13.1 requires tensorboard<1.14.0,>=1.13.0, which is not installed.\u001b[0m\n",
      "\u001b[31mbotocore 1.12.82 has requirement urllib3<1.25,>=1.20, but you'll have urllib3 1.25.8 which is incompatible.\u001b[0m\n",
      "Installing collected packages: tqdm, urllib3, certifi, idna, chardet, requests, tabulate, six, python-dateutil, numpy, pytz, pandas, lomond, jmespath, docutils, ibm-cos-sdk-core, ibm-cos-sdk-s3transfer, ibm-cos-sdk, watson-machine-learning-client-V4\n",
      "Successfully installed certifi-2019.11.28 chardet-3.0.4 docutils-0.15.2 ibm-cos-sdk-2.6.0 ibm-cos-sdk-core-2.6.0 ibm-cos-sdk-s3transfer-2.6.0 idna-2.8 jmespath-0.9.4 lomond-0.3.3 numpy-1.18.1 pandas-1.0.0 python-dateutil-2.8.1 pytz-2019.3 requests-2.22.0 six-1.14.0 tabulate-0.8.6 tqdm-4.42.1 urllib3-1.25.8 watson-machine-learning-client-V4-1.0.60\n",
      "\u001b[31mException:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/ibm/conda/miniconda3.6/lib/python3.6/site-packages/pip/_internal/cli/base_command.py\", line 176, in main\n",
      "    status = self.run(options, args)\n",
      "  File \"/opt/ibm/conda/miniconda3.6/lib/python3.6/site-packages/pip/_internal/commands/install.py\", line 441, in run\n",
      "    options.target_dir, target_temp_dir, options.upgrade\n",
      "  File \"/opt/ibm/conda/miniconda3.6/lib/python3.6/site-packages/pip/_internal/commands/install.py\", line 492, in _handle_target_dir\n",
      "    shutil.rmtree(target_item_dir)\n",
      "  File \"/home/spark/conda/envs/python3.6/lib/python3.6/shutil.py\", line 486, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/home/spark/conda/envs/python3.6/lib/python3.6/shutil.py\", line 424, in _rmtree_safe_fd\n",
      "    _rmtree_safe_fd(dirfd, fullname, onerror)\n",
      "  File \"/home/spark/conda/envs/python3.6/lib/python3.6/shutil.py\", line 428, in _rmtree_safe_fd\n",
      "    onerror(os.rmdir, fullname, sys.exc_info())\n",
      "  File \"/home/spark/conda/envs/python3.6/lib/python3.6/shutil.py\", line 426, in _rmtree_safe_fd\n",
      "    os.rmdir(name, dir_fd=topfd)\n",
      "OSError: [Errno 39] Directory not empty: 'window'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade watson-machine-learning-client-V4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os,os.path\n",
    "from watson_machine_learning_client import WatsonMachineLearningAPIClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Spark version and existence of Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The spark version is 2.3.4.\n"
     ]
    }
   ],
   "source": [
    "print('The spark version is {}.'.format(spark.version))\n",
    "# !pip install findspark\n",
    "# !pip install pyspark==2.3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('The spark version is {}.'.format(spark.version))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"install\"></a>\n",
    "##  Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports for Spark\n",
    "from pyspark.ml.feature import StringIndexer, IndexToString\n",
    "from pyspark.ml.feature import Bucketizer\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import Normalizer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.classification import NaiveBayes, DecisionTreeClassifier,RandomForestClassifier\n",
    "from pyspark.sql.functions import year\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "# Imports for pixiedust\n",
    "from pixiedust.display import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "<a id=\"object\"></a>\n",
    "## Read Data Asset - female_human_trafficking - See Lab Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-----------+--------------------+------+-------------------+-------------+------------------+--------------------+--------------------+-----------+---------------+----------------+---------------------+-----------------+-----------------------+----------------------------+--------------------+----------------------------+----------------------+------------------------------+----------------------+------------------------------+------------------------+--------------------+---+\n",
      "|INTERNAL_ID|VETTING_LEVEL|DESCRIPTION|                NAME|GENDER|         BIRTH_DATE|BIRTH_COUNTRY|BIRTH_COUNTRY_CODE|          OCCUPATION|             ADDRESS|        SSN|PASSPORT_NUMBER|PASSPORT_COUNTRY|PASSPORT_COUNTRY_CODE|COUNTRIES_VISITED|COUNTRIES_VISITED_COUNT|ARRIVAL_AIRPORT_COUNTRY_CODE|ARRIVAL_AIRPORT_IATA|ARRIVAL_AIRPORT_MUNICIPALITY|ARRIVAL_AIRPORT_REGION|DEPARTURE_AIRPORT_COUNTRY_CODE|DEPARTURE_AIRPORT_IATA|DEPARTURE_AIRPORT_MUNICIPALITY|DEPARTURE_AIRPORT_REGION|                UUID|AGE|\n",
      "+-----------+-------------+-----------+--------------------+------+-------------------+-------------+------------------+--------------------+--------------------+-----------+---------------+----------------+---------------------+-----------------+-----------------------+----------------------------+--------------------+----------------------------+----------------------+------------------------------+----------------------+------------------------------+------------------------+--------------------+---+\n",
      "|          1|          100|         NA|     Kathleen Bailey|     F|1985-11-27 00:00:00|        Ghana|                GH|         Chiropodist|79421 Jordan Orch...|885-71-9055|      240479506|           Ghana|                   GH|      AE,IE,RU,VN|                      4|                          US|                 BMI|          Bloomington/Normal|                 US-IL|                            AE|                   AUH|                     Abu Dhabi|                   AE-AZ|81d28245-a6d4-40e...| 31|\n",
      "|          2|           30|         NA|       Kelly Robbins|     F|1971-01-17 00:00:00|     Pakistan|                PK|Engineer, structural|5808 Jacobs Union...|141-10-9199|      449064032|        Pakistan|                   PK|         UA,UZ,IS|                      3|                          US|                 CLE|                   Cleveland|                 US-OH|                            UA|                   KBP|                          Kiev|                   UA-32|b4d817b3-2154-435...| 46|\n",
      "|          3|          100|         NA|       Linda Stewart|     F|1997-04-15 00:00:00|        Ghana|                GH|      Engineer, land|824 Kristin Grv, ...|011-46-5304|      639217810|           Ghana|                   GH|         RU,LK,ET|                      3|                          US|                 TPA|                       Tampa|                 US-FL|                            RU|                   KJA|                   Krasnoyarsk|                  RU-KYA|a52a6477-1f5e-4b0...| 19|\n",
      "|          4|           30|         NA|Stacey Courtney G...|     F|1984-03-27 00:00:00|        Ghana|                GH|     Careers adviser|322 Hutchinson Cr...|691-25-2647|      212838449|           Ghana|                   GH|               RU|                      1|                          US|                 TOL|                      Toledo|                 US-OH|                            RU|                   AER|                         Sochi|                  RU-KDA|5fcbbf15-8268-430...| 32|\n",
      "|          5|           30|         NA|  Erika Patie Fowler|     F|1998-06-18 00:00:00|        Ghana|                GH|Geneticist, molec...|07695 Michael Vis...|165-33-0802|       16514173|           Ghana|                   GH|            IE,AE|                      2|                          US|                 FWA|                  Fort Wayne|                 US-IN|                            IE|                   ORK|                          Cork|                    IE-C|6d1fe59a-6828-4bc...| 18|\n",
      "+-----------+-------------+-----------+--------------------+------+-------------------+-------------+------------------+--------------------+--------------------+-----------+---------------+----------------+---------------------+-----------------+-----------------------+----------------------------+--------------------+----------------------------+----------------------+------------------------------+----------------------+------------------------------+------------------------+--------------------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from pyspark.sql import SparkSession\n",
    "# sparkSession = SparkSession(spark).builder.getOrCreate()\n",
    "# # @hidden_cell\n",
    "# # The following code contains the credentials for a connection in your Project.\n",
    "# # You might want to remove those credentials before you share your notebook.\n",
    "# from project_lib import Project\n",
    "# project = Project.access()\n",
    "# female_human_trafficking_credentials = project.get_connected_data(name=\"female_human_trafficking\")\n",
    "# print(female_human_trafficking_credentials)\n",
    "# data_df_1 = sparkSession.read.format('jdbc') \\\n",
    "#     .option('url', '{}{}:{}/{}'.format('jdbc:db2://', female_human_trafficking_credentials['host'], '50000', female_human_trafficking_credentials['database'])) \\\n",
    "#     .option('dbtable', 'TRAFFICKING.FEMALE_HUMAN_TRAFFICKING') \\\n",
    "#     .option('user', female_human_trafficking_credentials['username']) \\\n",
    "#     .option('password', female_human_trafficking_credentials['password']).load()\n",
    "# data_df_1.show(5)\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "\n",
    "trafficking_df = SQLContext(sc).read.csv('/project_data/data_asset/female_human_trafficking.csv', header='true', inferSchema = 'true')\n",
    "trafficking_df.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data Asset - Occupations - See Lab Instructions\n",
    "The occupations listed in the female human trafficking file are too numerous to use as input to a machine learning model. We will categorize these occupations into 15 categories by joining with two other files. The Occupation.csv file contains a mapping of the occupations in the female human trafficking table to a category code. The Categories.csv file contains each code followed by the category name. This information needs to be joined to the female human trafficking table.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'assetfiles', 'guid': 'cd700957-2bbc-47b3-bdb5-06c3e848081b'}\n"
     ]
    }
   ],
   "source": [
    "# Insert Categories credentials in this cell after the comments\n",
    "# make CERTAIN that if credentials gets generated as credentials_1 or credentials_2 or credentials_n where n is a number\n",
    "# to rename as credentials\n",
    "#Put cursor on the next line to Insert to code \n",
    "from project_lib import Project\n",
    "project = Project.access()\n",
    "credentials = project.get_storage_metadata()\n",
    "print(credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+\n",
      "|          OCCUPATION|Code|\n",
      "+--------------------+----+\n",
      "|         Chiropodist|   6|\n",
      "|Engineer, structural|   2|\n",
      "|      Engineer, land|   2|\n",
      "|     Careers adviser|  15|\n",
      "|Geneticist, molec...|   7|\n",
      "+--------------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(OCCUPATION='Chiropodist', Code=6),\n",
       " Row(OCCUPATION='Engineer, structural', Code=2),\n",
       " Row(OCCUPATION='Engineer, land', Code=2),\n",
       " Row(OCCUPATION='Careers adviser', Code=15),\n",
       " Row(OCCUPATION='Geneticist, molecular', Code=7)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# credentials = {\n",
    "#     'endpoint' : credentials['URL'],\n",
    "#     'secret_key' : credentials['SECRET_KEY'], \n",
    "#     'access_key' : credentials['ACCESS_KEY'],\n",
    "#     'container' : credentials['BUCKET']\n",
    "# }\n",
    "\n",
    "# import ibmos2spark\n",
    "\n",
    "# cos = ibmos2spark.CloudObjectStorage(sc, credentials, auth_method='')\n",
    "\n",
    "# from pyspark.sql import SparkSession\n",
    "# spark = SparkSession.builder.getOrCreate()\n",
    "# occupations = spark.read\\\n",
    "#   .format('org.apache.spark.sql.execution.datasources.csv.CSVFileFormat')\\\n",
    "#   .option('header', 'true')\\\n",
    "#   .load(cos.url('data_asset/Occupation*.csv', credentials['container']))\n",
    "occupations = SQLContext(sc).read.csv('/project_data/data_asset/Occupation_csv_cotgztm25oru4xlskc5cgk2kb.csv', header='true', inferSchema = 'true')\n",
    "occupations.show(5)\n",
    "occupations.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data Asset - Categories - See Lab Instructions\n",
    "Follow the same procedure as above to insert a SparkDataFrame for Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert Categories credentials in this cell after the comments\n",
    "# make CERTAIN that if credentials gets generated as credentials_1 or credentials_2 or credentials_n where n is a number\n",
    "# to rename as credentials\n",
    "#Put cursor on the next line to Insert to code \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+\n",
      "|Code|            Category|\n",
      "+----+--------------------+\n",
      "|   1|       Sports/Travel|\n",
      "|   2|         Engineering|\n",
      "|   3|Information Techn...|\n",
      "|   4|          Journalism|\n",
      "|   5|          Government|\n",
      "+----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# credentials = {\n",
    "#     'endpoint' : credentials['URL'],\n",
    "#     'secret_key' : credentials['SECRET_KEY'], \n",
    "#     'access_key' : credentials['ACCESS_KEY'],\n",
    "#     'container' : credentials['BUCKET']\n",
    "# }\n",
    "\n",
    "# import ibmos2spark\n",
    "\n",
    "# cos = ibmos2spark.CloudObjectStorage(sc, credentials, auth_method='')\n",
    "\n",
    "# from pyspark.sql import SparkSession\n",
    "# spark = SparkSession.builder.getOrCreate()\n",
    "# categories = spark.read\\\n",
    "#   .format('org.apache.spark.sql.execution.datasources.csv.CSVFileFormat')\\\n",
    "#   .option('header', 'true')\\\n",
    "#   .load(cos.url('data_asset/Categories*.csv', credentials['container']))\n",
    "# categories.take(5)\n",
    "categories = SQLContext(sc).read.csv('/project_data/data_asset/Categories_csv_5hndzh0i3z7mfgl3tzpqa1s05.csv', header='true', inferSchema = 'true')\n",
    "categories.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join the Occupation mapping file content with the Category file content. \n",
    "The \"Code\" column serves as the matching key. Note that we can join the two flat files as if they were database tables using the DataFrame API.  In a similar fashion we will join the resulting DataFrame with the trafficking_df Dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|          OCCUPATION|    Category|\n",
      "+--------------------+------------+\n",
      "|         Chiropodist|     Medical|\n",
      "|Engineer, structural| Engineering|\n",
      "|      Engineer, land| Engineering|\n",
      "|     Careers adviser|       Other|\n",
      "|Geneticist, molec...|     Science|\n",
      "|Electronics engineer| Engineering|\n",
      "|Editor, commissio...|  Journalism|\n",
      "|              Writer|  Journalism|\n",
      "|Recruitment consu...|       Other|\n",
      "|     Theatre manager|        Arts|\n",
      "|        Statistician| Engineering|\n",
      "|Merchant navy off...|       Other|\n",
      "|Advertising accou...| Advertising|\n",
      "|Administrator, lo...|  Government|\n",
      "| Corporate treasurer|     Finance|\n",
      "|           Paramedic|     Medical|\n",
      "|Special effects a...|        Arts|\n",
      "|           Architect|Construction|\n",
      "|               Actor|        Arts|\n",
      "|      Science writer|  Journalism|\n",
      "+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "occupations_df = occupations.join(categories,'Code','inner').drop('Code')\n",
    "occupations_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+-------------+-----------+--------------------+------+-------------------+-------------+------------------+--------------------+-----------+---------------+----------------+---------------------+--------------------+-----------------------+----------------------------+--------------------+----------------------------+----------------------+------------------------------+----------------------+------------------------------+------------------------+--------------------+---+-----------+\n",
      "|          OCCUPATION|INTERNAL_ID|VETTING_LEVEL|DESCRIPTION|                NAME|GENDER|         BIRTH_DATE|BIRTH_COUNTRY|BIRTH_COUNTRY_CODE|             ADDRESS|        SSN|PASSPORT_NUMBER|PASSPORT_COUNTRY|PASSPORT_COUNTRY_CODE|   COUNTRIES_VISITED|COUNTRIES_VISITED_COUNT|ARRIVAL_AIRPORT_COUNTRY_CODE|ARRIVAL_AIRPORT_IATA|ARRIVAL_AIRPORT_MUNICIPALITY|ARRIVAL_AIRPORT_REGION|DEPARTURE_AIRPORT_COUNTRY_CODE|DEPARTURE_AIRPORT_IATA|DEPARTURE_AIRPORT_MUNICIPALITY|DEPARTURE_AIRPORT_REGION|                UUID|AGE|   Category|\n",
      "+--------------------+-----------+-------------+-----------+--------------------+------+-------------------+-------------+------------------+--------------------+-----------+---------------+----------------+---------------------+--------------------+-----------------------+----------------------------+--------------------+----------------------------+----------------------+------------------------------+----------------------+------------------------------+------------------------+--------------------+---+-----------+\n",
      "|         Chiropodist|        332|          100|         NA|    Cheryl Cind Lara|     F|1994-03-03 00:00:00|        Ghana|                GH|63589 Mcdaniel Po...|843-92-7552|      665662453|           Ghana|                   GH|         AE,PT,BS,PG|                      4|                          US|                 LCK|                    Columbus|                 US-OH|                            AE|                   SHJ|                       Sharjah|                   AE-SH|a7a951ca-681f-406...| 23|    Medical|\n",
      "|         Chiropodist|          1|          100|         NA|     Kathleen Bailey|     F|1985-11-27 00:00:00|        Ghana|                GH|79421 Jordan Orch...|885-71-9055|      240479506|           Ghana|                   GH|         AE,IE,RU,VN|                      4|                          US|                 BMI|          Bloomington/Normal|                 US-IL|                            AE|                   AUH|                     Abu Dhabi|                   AE-AZ|81d28245-a6d4-40e...| 31|    Medical|\n",
      "|Engineer, structural|        200|          100|         NA|          Sandr Hart|     F|1984-01-12 00:00:00|        Ghana|                GH|134 Kristine Stat...|758-98-4192|      493093544|           Ghana|                   GH|         KZ,BS,QA,IT|                      4|                          US|                 AVL|                   Asheville|                 US-NC|                            KZ|                   ALA|                        Almaty|                  KZ-ALM|eed47197-e540-4c3...| 33|Engineering|\n",
      "|Engineer, structural|          2|           30|         NA|       Kelly Robbins|     F|1971-01-17 00:00:00|     Pakistan|                PK|5808 Jacobs Union...|141-10-9199|      449064032|        Pakistan|                   PK|            UA,UZ,IS|                      3|                          US|                 CLE|                   Cleveland|                 US-OH|                            UA|                   KBP|                          Kiev|                   UA-32|b4d817b3-2154-435...| 46|Engineering|\n",
      "|      Engineer, land|        518|           30|         NA|  Genna Linda Wilson|     F|1997-04-11 00:00:00|        Ghana|                GH|0108 Kimberly Sho...|069-88-1269|      551047600|           Ghana|                   GH|SN,CO,CN,NG,KY,TH...|                      8|                          US|                 DCA|                  Washington|                 US-DC|                            SN|                   DKR|                         Dakar|                   SN-DK|150ad1af-b94b-4bd...| 19|Engineering|\n",
      "|      Engineer, land|          3|          100|         NA|       Linda Stewart|     F|1997-04-15 00:00:00|        Ghana|                GH|824 Kristin Grv, ...|011-46-5304|      639217810|           Ghana|                   GH|            RU,LK,ET|                      3|                          US|                 TPA|                       Tampa|                 US-FL|                            RU|                   KJA|                   Krasnoyarsk|                  RU-KYA|a52a6477-1f5e-4b0...| 19|Engineering|\n",
      "|     Careers adviser|        156|           20|         NA|        Evelyn Clark|     F|2001-01-25 00:00:00|        Ghana|                GH|12250 Williamson ...|565-87-0913|      811081996|           Ghana|                   GH|            AE,IT,KR|                      3|                          US|                 OAK|                     Oakland|                 US-CA|                            AE|                   SHJ|                       Sharjah|                   AE-SH|f36eccd3-c5d2-47d...| 16|      Other|\n",
      "|     Careers adviser|          4|           30|         NA|Stacey Courtney G...|     F|1984-03-27 00:00:00|        Ghana|                GH|322 Hutchinson Cr...|691-25-2647|      212838449|           Ghana|                   GH|                  RU|                      1|                          US|                 TOL|                      Toledo|                 US-OH|                            RU|                   AER|                         Sochi|                  RU-KDA|5fcbbf15-8268-430...| 32|      Other|\n",
      "|Geneticist, molec...|        400|           30|         NA|     Tiffany Wheeler|     F|2001-07-15 00:00:00|        Ghana|                GH|76136 Pamela Cent...|710-64-3816|      498422886|           Ghana|                   GH|            QA,FI,RU|                      3|                          US|                 SHV|                  Shreveport|                 US-LA|                            QA|                   DOH|                          Doha|                   QA-DA|b7af7d1e-4fb8-41d...| 15|    Science|\n",
      "|Geneticist, molec...|        279|          100|         NA|        Becky Miller|     F|1971-12-16 00:00:00|        Ghana|                GH|6786 Jeremy Drive...|042-44-1707|      790195497|           Ghana|                   GH|BZ,TH,LY,RU,PG,PT,KH|                      7|                          US|                 OKC|               Oklahoma City|                 US-OK|                            BZ|                   BZE|                   Belize City|                   BZ-BZ|3c2c6d86-caa4-471...| 45|    Science|\n",
      "|Geneticist, molec...|          5|           30|         NA|  Erika Patie Fowler|     F|1998-06-18 00:00:00|        Ghana|                GH|07695 Michael Vis...|165-33-0802|       16514173|           Ghana|                   GH|               IE,AE|                      2|                          US|                 FWA|                  Fort Wayne|                 US-IN|                            IE|                   ORK|                          Cork|                    IE-C|6d1fe59a-6828-4bc...| 18|    Science|\n",
      "|Electronics engineer|        324|          100|         NA|    Missy Laur Oneal|     F|1979-10-22 00:00:00|        Ghana|                GH|39432 Blake Run, ...|775-85-9925|      922356476|           Ghana|                   GH|                  OM|                      1|                          US|                 AUS|                      Austin|                 US-TX|                            OM|                   JNJ|                          Duqm|                   OM-WU|1d7564f0-a930-4a7...| 37|Engineering|\n",
      "|Electronics engineer|        316|           20|         NA|       Paula Jimenez|     F|2000-01-17 00:00:00|        Ghana|                GH|3750 Maxwell Moun...|018-05-3367|      196259211|           Ghana|                   GH|                  OM|                      1|                          US|                 ABQ|                 Albuquerque|                 US-NM|                            OM|                   JNJ|                          Duqm|                   OM-WU|f3ebb47f-df45-4de...| 17|Engineering|\n",
      "|Electronics engineer|          6|          100|         NA|       Ashlee Fisher|     F|1981-01-05 00:00:00|        Ghana|                GH|4838 Cassandra St...|072-16-8742|      513428119|           Ghana|                   GH|            AE,SG,JM|                      3|                          US|                 OKC|               Oklahoma City|                 US-OK|                            AE|                   AUH|                     Abu Dhabi|                   AE-AZ|b5c7e0a7-56b6-4f3...| 36|Engineering|\n",
      "|Editor, commissio...|        306|          100|         NA|Rebecc Chrissie M...|     F|1976-12-17 00:00:00|        Ghana|                GH|928 Kelly Run Apt...|390-17-5341|       69331870|           Ghana|                   GH|   HR,SK,UZ,ES,GH,PL|                      6|                          US|                 LBB|                     Lubbock|                 US-TX|                            HR|                   ZAG|                        Zagreb|                   HR-21|5d4afafd-06ac-465...| 40| Journalism|\n",
      "|Editor, commissio...|          7|          100|         NA|    Jacqueline Clark|     F|1976-01-19 00:00:00|        Ghana|                GH|1148 Wang Fall Su...|634-03-1462|      742709558|           Ghana|                   GH|IS,KW,CL,OM,GB,CZ,BY|                      7|                          US|                 TUS|                      Tucson|                 US-AZ|                            IS|                   KEF|                     ReykjavÃ­k|                    IS-2|077fc1af-1802-40a...| 41| Journalism|\n",
      "|              Writer|        542|          100|         NA|        Angel Howell|     F|1984-02-12 00:00:00|        Ghana|                GH|938 Miller Island...|508-58-5765|       95692208|           Ghana|                   GH|EE,KR,TN,OM,SD,RO...|                     10|                          US|                 HSV|                  Huntsville|                 US-AL|                            EE|                   TLL|                       Tallinn|                   EE-37|e16959c2-19fb-4fc...| 33| Journalism|\n",
      "|              Writer|          8|           30|         NA|       Shell Chapman|     F|1997-08-24 00:00:00|        Ghana|                GH|72346 Wilson Ford...|004-07-1446|      170002642|           Ghana|                   GH|KW,SA,JO,BE,KH,QA...|                      8|                          US|                 DLF|                     Del Rio|                 US-TX|                            KW|                   KWI|                   Kuwait City|                   KW-FA|fb3808ae-b5f8-482...| 19| Journalism|\n",
      "|Recruitment consu...|         93|           10|         NA|         Barbara Fox|     F|1988-12-09 00:00:00|        Ghana|                GH|826 Frey Loop Apt...|039-26-3960|      945571808|           Ghana|                   GH|GE,IT,BY,RU,IR,SE,ME|                      7|                          US|                 OKC|               Oklahoma City|                 US-OK|                            GE|                   TBS|                       Tbilisi|                   GE-TB|546672df-b54d-4e1...| 28|      Other|\n",
      "|Recruitment consu...|         42|           10|         NA|Nancy Stephanie T...|     F|1988-01-09 00:00:00|        Ghana|                GH|1397 Morgan Locks...|356-98-2006|      508156759|           Ghana|                   GH|   BA,MX,LV,DO,GH,RU|                      6|                          US|                 FWA|                  Fort Wayne|                 US-IN|                            BA|                   SJJ|                      Sarajevo|                  BA-BIH|0f1e790d-e94f-4b1...| 29|      Other|\n",
      "+--------------------+-----------+-------------+-----------+--------------------+------+-------------------+-------------+------------------+--------------------+-----------+---------------+----------------+---------------------+--------------------+-----------------------+----------------------------+--------------------+----------------------------+----------------------+------------------------------+----------------------+------------------------------+------------------------+--------------------+---+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trafficking_df = trafficking_df.join(occupations_df,'OCCUPATION','inner')\n",
    "trafficking_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"transform\"></a>\n",
    "## Identify our labels and transform \n",
    "\n",
    "We will use the 'VETTING_LEVEL' column as a label for training the machine learning model.  This is where our analyst has marked the data as vetted.  \n",
    "\n",
    "Spark ML requires that that the labels are data type Double, so we will cast the  column as Double.\n",
    "\n",
    "withColumn() is a Spark SQL way to manipulate a dataframe.  Since an RDD is immutable, we create a new RDD each time we transform.  This code creates a new column VettingTemp and sets it to the values in \"VETTING_LEVEL\" cast to a Double.    It then drops column VETTING_LEVEL and renames column VettingTemp to VETTING_LEVEL.\n",
    "\n",
    "We will also do a similar manipulation for the COUNTRIES_VISITED_COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataWithLabels = (trafficking_df.withColumn(\"VettingTemp\", trafficking_df[\"VETTING_LEVEL\"]\n",
    "    .cast(\"Double\")).drop(\"VETTING_LEVEL\").withColumnRenamed(\"VettingTemp\", \"VETTING_LEVEL\"))\n",
    "\n",
    "DataWithLabels = (trafficking_df.withColumn(\"CountriesVisitedCountTemp\", trafficking_df[\"COUNTRIES_VISITED_COUNT\"]\n",
    "    .cast(\"Double\")).drop(\"COUNTRIES_VISITED_COUNT\").withColumnRenamed(\"CountriesVisitedCountTemp\", \"COUNTRIES_VISITED_COUNT\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to use year of birth intead of date of birth in our learning.  \n",
    "\n",
    "Another way to transform an rdd in Spark is using SQL Syntax.  Here, we will be adding a new field, BIRTH_YEAR to our vetting set.  We will also just select the fields we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "816"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataWithLabels.createOrReplaceTempView(\"VettingData\")\n",
    "AllVettingData = sqlContext.sql (\"SELECT UUID, VETTING_LEVEL, NAME, Category, COUNTRIES_VISITED_COUNT, PASSPORT_COUNTRY_CODE, year(BIRTH_DATE) as BIRTH_YEAR, 1 as Counter FROM VettingData\")\n",
    "FilteredVettingData = AllVettingData.filter(\"VETTING_LEVEL==100\")\n",
    "FilteredVettingData.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use pixiedust to visually explore the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "aggregation": "COUNT",
      "charttype": "stacked",
      "clusterby": "VETTING_LEVEL",
      "handlerId": "barChart",
      "keyFields": "COUNTRIES_VISITED_COUNT"
     }
    }
   },
   "outputs": [],
   "source": [
    "display(AllVettingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's look at the data we have:\n",
    "\n",
    "VETTING_LEVEL is in four different statuses:\n",
    "\n",
    "    10 - HIGH\n",
    "    \n",
    "    20 - MEDIUM\n",
    "    \n",
    "    30 - LOW\n",
    "    \n",
    "    100 - Unlabeled\n",
    "\n",
    "\n",
    "Print the total number of vetting statuses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows labeled high is 69.\n",
      "The number of rows labeled medium is 95.\n",
      "The number of rows labeled low is 105.\n",
      "The number of unlabeled rows is 816.\n"
     ]
    }
   ],
   "source": [
    "print('The number of rows labeled high is {}.'.format(AllVettingData.filter(AllVettingData['VETTING_LEVEL'] == 10).count()))\n",
    "print('The number of rows labeled medium is {}.'.format(AllVettingData.filter(AllVettingData['VETTING_LEVEL'] == 20).count()))\n",
    "print('The number of rows labeled low is {}.'.format(AllVettingData.filter(AllVettingData['VETTING_LEVEL'] == 30).count()))\n",
    "print('The number of unlabeled rows is {}.'.format(AllVettingData.filter(AllVettingData['VETTING_LEVEL'] == 100).count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The majority of the data has not been labeled (VETTING_LABEL=100 means unvetted).  We can not use it for our training data, so filter it out.\n",
    "Print the total number of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "269"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LabeledVettingData=AllVettingData.filter(\"VETTING_LEVEL != 100\")\n",
    "LabeledVettingData.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "aggregation": "COUNT",
      "charttype": "stacked",
      "clusterby": "VETTING_LEVEL",
      "handlerId": "barChart",
      "keyFields": "COUNTRIES_VISITED_COUNT",
      "rendererId": "matplotlib",
      "tableFields": "COUNTRIES_VISITED_COUNT"
     }
    }
   },
   "outputs": [],
   "source": [
    "display(LabeledVettingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"engineering\"></a>\n",
    "## Feature Engineering.\n",
    "### A feature is the elements of the data that we are using in our learning.  We need to transform each one of our features into a format that SparkML can use it.\n",
    "More about the choices for feature engineering can be found here:\n",
    "http://spark.apache.org/docs/2.0.0/ml-features.html#stringindexer\n",
    "\n",
    "\n",
    "The first thing we will do is transform our labels (VETTING_LEVEL) into a format that we can use in the algorithm, and then get back to 'human readable' from in the end. The ML models require that the labels are in a column called 'label'.    The converter helps us transform these back in the end.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelIndexer = StringIndexer(inputCol=\"VETTING_LEVEL\", outputCol=\"label\", handleInvalid=\"error\")\n",
    "labelModel = labelIndexer.fit(LabeledVettingData)\n",
    "converter = IndexToString(inputCol=\"prediction\", outputCol=\"predCategory\", labels=labelModel.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will process all of the features we will use. While there are a variety of choices for transforming elements, we will treat each as a String using the StringIndexer.\n",
    "\n",
    "StringIndexer is a transformer that encodes a string column to a column of indices. The indices are ordered by value frequencies, so the most frequent value gets index 0. If the input column is numeric, it is cast to string first.\n",
    "\n",
    "For our vetting dataset, we are interested in all string based features so we will use the StringIndexer for them.  We need to use 'handleInvalid=\"skip\"' because not all values have been validated in our vetting set.  That means the algorithms will skip these records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoryIndexer = StringIndexer(inputCol=\"Category\", outputCol=\"categoryIndex\", handleInvalid=\"skip\")\n",
    "countryIndexer = StringIndexer(inputCol=\"PASSPORT_COUNTRY_CODE\", outputCol=\"countryIndex\", handleInvalid=\"skip\")\n",
    "yearOfBirthIndexer = StringIndexer(inputCol=\"BIRTH_YEAR\", outputCol=\"birthYearIndex\", handleInvalid=\"skip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, put all of our features into a simple array using a VectorAssembler.\n",
    "\n",
    "Note that COUNTRIIES_VISITED_COUNT is already a numeric, so we can just put that in the array as is.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecAssembler = VectorAssembler(inputCols=[\"categoryIndex\",\"countryIndex\",\"birthYearIndex\", \"COUNTRIES_VISITED_COUNT\"], outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizer will help us normalize the features into a standard frmat.  It can help us improve the behavior of the learning algorithms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = Normalizer(inputCol=\"features\", outputCol=\"normFeatures\", p=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"model\"></a>\n",
    "## Declare the model that we want to use\n",
    "\n",
    "The model here is Naive Bayes.  It will output each prediction into a 'prediction' column.  Naive Bayes  is a probabistic model that learns based on previous decisions.  We will take a best guess at the paramater 'smoothing'- SparkML will help us tune it later!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = NaiveBayes(smoothing=1.0, featuresCol=\"normFeatures\",modelType=\"multinomial\", labelCol=\"label\", predictionCol=\"prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pipeline\"></a>\n",
    "## Setup the Pipeline\n",
    "\n",
    "The pipeline is the guts of the algorithm that strings all the work we've done together.\n",
    "\n",
    "The stages are run in order and the input DataFrame is transformed as it passes through each stage.   First, comes the feature transformations, then the assembler to put them togather into one DF.  We pass that into the model. \n",
    "\n",
    "In machine learning, it is common to run a sequence of algorithms to process and learn from data, so this can get as complex as we want to make it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[labelIndexer,categoryIndexer,countryIndexer, yearOfBirthIndexer, vecAssembler, normalizer, nb, converter])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"train\"></a>\n",
    "## Train the model\n",
    "\n",
    "We will split it into training data which is marked and test data which will be used to test the efficiency of the algorithms.\n",
    "\n",
    "It is common to split the split up the data randomly into 70% for training and 30% for testing.  If we were to use a bigger training set, we might use an 80% / 20% split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of records in the training data set is 194.\n",
      "The number of rows labeled high is 54.\n",
      "The number of rows labeled medium is 65.\n",
      "The number of rows labeled low is 75.\n",
      "\n",
      "The number of records in the test data set is 75.\n",
      "The number of rows labeled high is 15.\n",
      "The number of rows labeled medium is 30.\n",
      "The number of rows labeled low is 30.\n"
     ]
    }
   ],
   "source": [
    "train, test = LabeledVettingData.randomSplit([70.0,30.0], seed=152345)\n",
    "train.cache()\n",
    "test.cache()\n",
    "print('The number of records in the training data set is {}.'.format(train.count()))\n",
    "print('The number of rows labeled high is {}.'.format(train.filter(train['VETTING_LEVEL'] == 10).count()))\n",
    "print('The number of rows labeled medium is {}.'.format(train.filter(train['VETTING_LEVEL'] == 20).count()))\n",
    "print('The number of rows labeled low is {}.'.format(train.filter(train['VETTING_LEVEL'] == 30).count()))\n",
    "print('')\n",
    "\n",
    "print('The number of records in the test data set is {}.'.format(test.count()))\n",
    "print('The number of rows labeled high is {}.'.format(test.filter(test['VETTING_LEVEL'] == 10).count()))\n",
    "print('The number of rows labeled medium is {}.'.format(test.filter(test['VETTING_LEVEL'] == 20).count()))\n",
    "print('The number of rows labeled low is {}.'.format(test.filter(test['VETTING_LEVEL'] == 30).count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the pipeline to the training data.  This will run the data through the algorithm to train it based on our labled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the pipeline to the training data assigning the result to a variable called 'model'.\n",
    "model = pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions on records in the Test data set.  This will test the model based on the 30% data we have left in reserve.  Keep in mind that the model has not seen the data in the test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data assigning the result to a variable called 'predictions'.\n",
    "predictions = model.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"evaluate\"></a>\n",
    "## Show and Evaluate Results\n",
    "\n",
    "Note that we only got a small sample of the results back because we have a very small amount of training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SparkML has automated ways to look at result quality called Evaluators.  More information can be found here:\n",
    "http://spark.apache.org/docs/latest/mllib-evaluation-metrics.html\n",
    "\n",
    "For simplicity here, we will use a a common evaluation method called Reciever Operator Characteristic.  This genenerally is used for binary classifiers, but we will use it because we only have 3 levels of prediction.\n",
    "\n",
    "The curve is created by plotting the true positive rate against the false positive rate at various threshold settings. The ROC curve is thus the sensitivity as a function of fall-out. The area under the ROC curve is useful for comparing and selecting the best machine learning model for a given data set. A model with an area under the ROC curve score near 1 has very good performance. A model with a score near 0.5 is about as good as flipping a coin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under the ROC curve = 0.7601532567049809.\n"
     ]
    }
   ],
   "source": [
    "evaluator = BinaryClassificationEvaluator().setLabelCol(\"label\").setMetricName(\"areaUnderROC\")\n",
    "print('Area under the ROC curve = {}.'.format(evaluator.evaluate(predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tuning\"></a>\n",
    "## Automatic Algorithm Tuning - Also Called  Hyperparameter Tuning\n",
    "\n",
    "\n",
    "Spark ML algorithms provide many hyperparameters for tuning models. These hyperparameters are distinct from the model parameters being optimized by Spark ML itself.  Hyperparameter tuning is accomplished by choosing the best set of parameters based on model performance on test data that the model was not trained with. All combinations of hyperparameters specified will be tried in order to find the one that leads to the model with the best evaluation result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will build a paramater grid to tell SparkML what to change in its testing.  Note that we are changing all the paramaters we setup in our pipeline before - the 'smoothing' in our model, and the normalizer parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid = (ParamGridBuilder().addGrid(nb.smoothing, [0.50,0.75,1.0])\n",
    "                 .addGrid(normalizer.p, [1.0, 1.25, 1.5]).build())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, create a cross validator to tune the pipeline with the generated parameter grid.  Cross-validation attempts to fit the underlying estimator with user-specified combinations of parameters, cross-evaluate the fitted models, and output the best one.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CrossValidator().setEstimator(pipeline).setEvaluator(evaluator).setEstimatorParamMaps(paramGrid).setNumFolds(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will run the models through the grid we set above.  It runs a cross evaluation of the ML Pipeline to find the best model.  Note that since runs the model several times, it takes a few minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under the ROC curve for best fitted model = 0.7540229885057472.\n"
     ]
    }
   ],
   "source": [
    "cvModel = cv.fit(train)\n",
    "print('Area under the ROC curve for best fitted model = {}.'.format(evaluator.evaluate(cvModel.transform(test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what improvement we achieve by tuning the hyperparameters using cross-evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under the ROC curve for non-tuned model = 0.7601532567049809.\n",
      "Area under the ROC curve for best fitted model = 0.7540229885057472.\n",
      "Improvement = -0.81%\n"
     ]
    }
   ],
   "source": [
    "print('Area under the ROC curve for non-tuned model = {}.'.format(evaluator.evaluate(predictions)))\n",
    "print('Area under the ROC curve for best fitted model = {}.'.format(evaluator.evaluate(cvModel.transform(test))))\n",
    "print('Improvement = {0:0.2f}%'.format((evaluator.evaluate(cvModel.transform(test)) - evaluator.evaluate(predictions)) *100 / evaluator.evaluate(predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"score\"></a>\n",
    "## Score the remaining records that were unscored, and load them into a Data Warehouse table. \n",
    "\n",
    "First, we want to only get the unvetted records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "NewVettingData=AllVettingData.filter(\"VETTING_LEVEL == 100\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, transform the new model with the new vetting records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "newPreds = cvModel.transform(NewVettingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Show the data we have predicted and some of the fields in the data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+------------+--------------------+--------------------+-----------------------+---------------------+\n",
      "|                UUID|prediction|predCategory|         probability|                NAME|COUNTRIES_VISITED_COUNT|PASSPORT_COUNTRY_CODE|\n",
      "+--------------------+----------+------------+--------------------+--------------------+-----------------------+---------------------+\n",
      "|a7a951ca-681f-406...|       1.0|          20|[0.31164812553745...|    Cheryl Cind Lara|                    4.0|                   GH|\n",
      "|81d28245-a6d4-40e...|       1.0|          20|[0.32044175065574...|     Kathleen Bailey|                    4.0|                   GH|\n",
      "|eed47197-e540-4c3...|       1.0|          20|[0.35404715998879...|          Sandr Hart|                    4.0|                   GH|\n",
      "|a52a6477-1f5e-4b0...|       0.0|          30|[0.51314715521269...|       Linda Stewart|                    3.0|                   GH|\n",
      "|3c2c6d86-caa4-471...|       0.0|          30|[0.38784819192622...|        Becky Miller|                    7.0|                   GH|\n",
      "|1d7564f0-a930-4a7...|       1.0|          20|[0.36999911731975...|    Missy Laur Oneal|                    1.0|                   GH|\n",
      "|b5c7e0a7-56b6-4f3...|       1.0|          20|[0.35214750912941...|       Ashlee Fisher|                    3.0|                   GH|\n",
      "|5d4afafd-06ac-465...|       0.0|          30|[0.42411479405855...|Rebecc Chrissie M...|                    6.0|                   GH|\n",
      "|077fc1af-1802-40a...|       0.0|          30|[0.42211043632126...|    Jacqueline Clark|                    7.0|                   GH|\n",
      "|e16959c2-19fb-4fc...|       0.0|          30|[0.37490414987086...|        Angel Howell|                   10.0|                   GH|\n",
      "|d3d03e87-275a-43b...|       1.0|          20|[0.32465131915972...|     Jasmine Collins|                    8.0|                   GH|\n",
      "|86b0b0b7-0ffa-424...|       1.0|          20|[0.32013476338618...|         Linda Scott|                    3.0|                   GH|\n",
      "|d4252e23-2f33-42b...|       1.0|          20|[0.33001851764103...|       Ashley Gibson|                   11.0|                   GH|\n",
      "|5825742a-6236-429...|       1.0|          20|[0.34307680637798...|Shelle Teri Fitzg...|                    2.0|                   GH|\n",
      "|2145d491-f308-4c7...|       0.0|          30|[0.43766202819269...|   Tammy Sara Garcia|                    3.0|                   GH|\n",
      "|bfadfaa3-4dba-4f7...|       0.0|          30|[0.51527572883476...|        Anna Carlson|                    4.0|                   GH|\n",
      "|d9123832-4794-4be...|       0.0|          30|[0.49671532731129...|        Missy Little|                    1.0|                   GH|\n",
      "|bcb302a3-7eb7-477...|       0.0|          30|[0.51861691404684...| Joan Donna Cummings|                    1.0|                   GH|\n",
      "|e7bb9c60-9411-40e...|       0.0|          30|[0.47401546544012...|Becky Cynthia Sta...|                    5.0|                   GH|\n",
      "|b6d07693-b52a-427...|       1.0|          20|[0.34780059269995...|        Cheryl Smith|                    4.0|                   GH|\n",
      "+--------------------+----------+------------+--------------------+--------------------+-----------------------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newPreds.select(\"UUID\", \"prediction\", \"predCategory\", \"probability\", \"NAME\", \"COUNTRIES_VISITED_COUNT\", \"PASSPORT_COUNTRY_CODE\" ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that VETTING_LEVEL is in three different statuses:\n",
    "\n",
    "\n",
    "10- HIGH\n",
    "\n",
    "20- MEDIUM\n",
    "\n",
    "30 - LOW\n",
    "\n",
    "\n",
    "Let's print the total number of vetting statuses that we predicted.  The actual predicted data is low because we only have a few vetted records.  Remember that we had to 'skip' and features that were not in our trained data, so if we didn't have someone who was born in a certain year in our training data, we won't be able to predict a result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of records in the unvetted data set is 775.\n",
      "The number of rows labeled high is 0.\n",
      "The number of rows labeled medium is 401.\n",
      "The number of rows labeled low is 374.\n"
     ]
    }
   ],
   "source": [
    "print('The number of records in the unvetted data set is {}.'.format(newPreds.count()))\n",
    "print('The number of rows labeled high is {}.'.format(newPreds.filter(newPreds['predCategory'] == 10).count()))\n",
    "print('The number of rows labeled medium is {}.'.format(newPreds.filter(newPreds['predCategory'] == 20).count()))\n",
    "print('The number of rows labeled low is {}.'.format(newPreds.filter(newPreds['predCategory'] == 30).count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"credentials\"></a>\n",
    "## Insert the database credentials - see Lab Instructions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'database': 'BLUDB', 'password': 'N@9pxLAaCe7jTz2WwztTP0oZH31bc', 'host': 'db2w-iwcuhlb.us-south.db2w.cloud.ibm.com', 'username': 'bluadmin'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# @hidden_cell\n",
    "# The following code contains the credentials for a connection in your Project.\n",
    "# You might want to remove those credentials before you share your notebook.\n",
    "credentials = project.get_connection(name=\"trafficking\")\n",
    "print(credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"write\"></a>\n",
    "## Write the results to the DB2 Warehouse. Please replace BLB in the Table_Name with your initials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "valuesToWrite= newPreds.select(\"UUID\",  \"predCategory\",\"Category\")\n",
    "#Please replace BLB below with your initials. \n",
    "table_Name = \"FEMALE_HUMAN_TRAFFICKING_MC_ML_RESULTS\"\n",
    "\n",
    "from ingest.Connectors import Connectors\n",
    "\n",
    "dashdbsaveoption = {\n",
    "                     Connectors.DASHDB.HOST              : credentials[\"host\"],\n",
    "                     Connectors.DASHDB.DATABASE          : credentials[\"database\"],\n",
    "                     Connectors.DASHDB.USERNAME          : credentials[\"username\"],\n",
    "                     Connectors.DASHDB.PASSWORD          : credentials[\"password\"],\n",
    "                     Connectors.DASHDB.TARGET_TABLE_NAME : table_Name,\n",
    "                     Connectors.DASHDB.TARGET_WRITE_MODE : 'insert' }\n",
    "\n",
    "NewdashDBDF = valuesToWrite.write.format(\"com.ibm.spark.discover\").options(**dashdbsaveoption).save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Random Forest Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under the ROC curve = 0.778544061302682.\n",
      "The number of records in the unvetted data set is 775.\n",
      "The number of rows labeled high is 118.\n",
      "The number of rows labeled medium is 170.\n",
      "The number of rows labeled low is 487.\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier().setLabelCol(\"label\").setFeaturesCol(\"normFeatures\").setNumTrees(20)\n",
    "# Create new Pipeline using the RandomForest model and all the same feature transformers used above for logistic regression\n",
    "pipelineRF = Pipeline(stages=[labelIndexer,categoryIndexer,countryIndexer, yearOfBirthIndexer, vecAssembler, normalizer, rf, converter])\n",
    "\n",
    "# Train model.\n",
    "modelRF = pipelineRF.fit(train)\n",
    "\n",
    "# Make predictions.\n",
    "predictionsRF = modelRF.transform(test)\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator().setLabelCol(\"label\").setMetricName(\"areaUnderROC\")\n",
    "print('Area under the ROC curve = {}.'.format(evaluator.evaluate(predictionsRF)))\n",
    "\n",
    "newRFPreds = modelRF.transform(NewVettingData)\n",
    "\n",
    "print('The number of records in the unvetted data set is {}.'.format(newRFPreds.count()))\n",
    "print('The number of rows labeled high is {}.'.format(newRFPreds.filter(newRFPreds['predCategory'] == 10).count()))\n",
    "print('The number of rows labeled medium is {}.'.format(newRFPreds.filter(newRFPreds['predCategory'] == 20).count()))\n",
    "print('The number of rows labeled low is {}.'.format(newRFPreds.filter(newRFPreds['predCategory'] == 30).count()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model - This section below demonstrates the Watson Machine Language API which allows you to programmatically save the model that was trained to a model repository.  The model can then be deployed for use in a production application.  \n",
    "\n",
    "\n",
    "### You will leverage the Machine Learning service that was created in the Lab prerequisites.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VybmFtZSI6Im1pY2hhZWwuY3JvbmsiLCJyb2xlIjoiVXNlciIsInBlcm1pc3Npb25zIjpbImFjY2Vzc19jYXRhbG9nIiwiYWNjZXNzX2luZm9ybWF0aW9uX2Fzc2V0cyIsInZpZXdfcXVhbGl0eSIsInZpcnR1YWxpemVfdHJhbnNmb3JtIiwibWFuYWdlX2luZm9ybWF0aW9uX2Fzc2V0cyIsImFjY2Vzc19xdWFsaXR5IiwibWFuYWdlX2Rpc2NvdmVyeSIsIm1hbmFnZV9tZXRhZGF0YV9pbXBvcnQiLCJhdXRob3JfZ292ZXJuYW5jZV9hcnRpZmFjdHMiLCJjYW5fcHJvdmlzaW9uIiwibWFuYWdlX3F1YWxpdHkiXSwic3ViIjoibWljaGFlbC5jcm9uayIsImlzcyI6IktOT1hTU08iLCJhdWQiOiJEU1giLCJ1aWQiOiIxMDAwMzMxMDE2IiwiYXV0aGVudGljYXRvciI6ImRlZmF1bHQiLCJpYXQiOjE1ODA3NTIxMDUsImV4cCI6MTU4MDc5NTMwNX0.ehEmeZrEJIXFuV4gTR-cOs82CRvqA8DEBRJEBvFo4oMBb2EtCPsdeuvAjCBSiBmr7cvPxjI5xk3dRLBt4GA2s451CGtasqW8_9bfLLMIULLeM8DAJRUKTm49Ad1wfvZN1CKtCGj1VnBcS4cO5xac_lSxOjnA_mnUTSV2_ViYJeEYYULIbZZDB4aNvvjDGLj6srz5a9XD2M5bXrYm3nnmb7t60DW0optBNF2XGGvlZfZns1dMSLMaO2V2ZF1xHtKvGYW1noqaLwD2VbeZHy60BGXIA8k9lBfptPURk1uxBvnzPAxuw6Fo3loJwNpOehewrgosWXszWAyJKlTbBjYLNQ\n",
      "1.0.60\n"
     ]
    }
   ],
   "source": [
    "import sys,os,os.path\n",
    "#token = os.environ['USER_ACCESS_TOKEN']\n",
    "token = \"eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VybmFtZSI6Im1pY2hhZWwuY3JvbmsiLCJyb2xlIjoiVXNlciIsInBlcm1pc3Npb25zIjpbImFjY2Vzc19jYXRhbG9nIiwiYWNjZXNzX2luZm9ybWF0aW9uX2Fzc2V0cyIsInZpZXdfcXVhbGl0eSIsInZpcnR1YWxpemVfdHJhbnNmb3JtIiwibWFuYWdlX2luZm9ybWF0aW9uX2Fzc2V0cyIsImFjY2Vzc19xdWFsaXR5IiwibWFuYWdlX2Rpc2NvdmVyeSIsIm1hbmFnZV9tZXRhZGF0YV9pbXBvcnQiLCJhdXRob3JfZ292ZXJuYW5jZV9hcnRpZmFjdHMiLCJjYW5fcHJvdmlzaW9uIiwibWFuYWdlX3F1YWxpdHkiXSwic3ViIjoibWljaGFlbC5jcm9uayIsImlzcyI6IktOT1hTU08iLCJhdWQiOiJEU1giLCJ1aWQiOiIxMDAwMzMxMDE2IiwiYXV0aGVudGljYXRvciI6ImRlZmF1bHQiLCJpYXQiOjE1ODA3NTIxMDUsImV4cCI6MTU4MDc5NTMwNX0.ehEmeZrEJIXFuV4gTR-cOs82CRvqA8DEBRJEBvFo4oMBb2EtCPsdeuvAjCBSiBmr7cvPxjI5xk3dRLBt4GA2s451CGtasqW8_9bfLLMIULLeM8DAJRUKTm49Ad1wfvZN1CKtCGj1VnBcS4cO5xac_lSxOjnA_mnUTSV2_ViYJeEYYULIbZZDB4aNvvjDGLj6srz5a9XD2M5bXrYm3nnmb7t60DW0optBNF2XGGvlZfZns1dMSLMaO2V2ZF1xHtKvGYW1noqaLwD2VbeZHy60BGXIA8k9lBfptPURk1uxBvnzPAxuw6Fo3loJwNpOehewrgosWXszWAyJKlTbBjYLNQ\"\n",
    "print(token)\n",
    "wml_credentials = {\n",
    "                     \"token\": token,\n",
    "                     \"instance_id\" : \"wml_local\",\n",
    "                     \"url\": \"https://10.75.17.115:32215\",\n",
    "                     \"version\": \"2.5.0\"\n",
    "}\n",
    "client = WatsonMachineLearningAPIClient(wml_credentials)\n",
    "print(client.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------  --------------------  ------------------------\n",
      "GUID                                  NAME                  CREATED\n",
      "cc1e19e2-20d8-4341-a442-2dfd5ea84377  JAIC                  2020-01-30T16:15:33.149Z\n",
      "ad49bdb4-8cce-4854-af6c-c9f7a171be40  JCF Deployment Space  2020-01-29T00:43:15.716Z\n",
      "------------------------------------  --------------------  ------------------------\n"
     ]
    }
   ],
   "source": [
    "client.repository.list_spaces()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.repository.list_models()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98d6a078-7669-4e6c-9168-15994486dbc9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'SUCCESS'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_id = os.environ['PROJECT_ID']\n",
    "print(project_id)\n",
    "client.set.default_project(project_id)\n",
    "#client.repository.ModelMetaNames.show()\n",
    "# client.set.default_space(\"ad49bdb4-8cce-4854-af6c-c9f7a171be40\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsetting the project_id ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'SUCCESS'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_props = {\n",
    "        client.repository.ModelMetaNames.NAME: \"FHT_Spark4\",\n",
    "        client.repository.ModelMetaNames.TYPE: \"mllib_2.3\",\n",
    "        client.repository.ModelMetaNames.RUNTIME_UID: \"spark-mllib_2.3\"\n",
    "}\n",
    "client.set.default_space(\"ad49bdb4-8cce-4854-af6c-c9f7a171be40\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After the cell below is executed, a model entry \"FHT Spark\" will appear in the Project Model section. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metadata': {'guid': '00d8610f-9c1d-4538-bd6f-522c0c6e534c',\n",
       "  'id': '00d8610f-9c1d-4538-bd6f-522c0c6e534c',\n",
       "  'modified_at': '2020-02-03T17:49:11.002Z',\n",
       "  'created_at': '2020-02-03T17:49:07.002Z',\n",
       "  'owner': '1000331016',\n",
       "  'href': '/v4/models/00d8610f-9c1d-4538-bd6f-522c0c6e534c?space_id=ad49bdb4-8cce-4854-af6c-c9f7a171be40'},\n",
       " 'entity': {'name': 'FHT_Spark4',\n",
       "  'training_data_references': [{'location': {'bucket': 'not_applicable'},\n",
       "    'type': 'fs',\n",
       "    'connection': {'access_key_id': 'not_applicable',\n",
       "     'secret_access_key': 'not_applicable',\n",
       "     'endpoint_url': 'not_applicable'},\n",
       "    'schema': {'id': '1',\n",
       "     'type': 'struct',\n",
       "     'fields': [{'name': 'UUID',\n",
       "       'type': 'string',\n",
       "       'nullable': True,\n",
       "       'metadata': {}},\n",
       "      {'name': 'VETTING_LEVEL',\n",
       "       'type': 'integer',\n",
       "       'nullable': True,\n",
       "       'metadata': {'modeling_role': 'target'}},\n",
       "      {'name': 'NAME', 'type': 'string', 'nullable': True, 'metadata': {}},\n",
       "      {'name': 'Category', 'type': 'string', 'nullable': True, 'metadata': {}},\n",
       "      {'name': 'COUNTRIES_VISITED_COUNT',\n",
       "       'type': 'double',\n",
       "       'nullable': True,\n",
       "       'metadata': {}},\n",
       "      {'name': 'PASSPORT_COUNTRY_CODE',\n",
       "       'type': 'string',\n",
       "       'nullable': True,\n",
       "       'metadata': {}},\n",
       "      {'name': 'BIRTH_YEAR',\n",
       "       'type': 'integer',\n",
       "       'nullable': True,\n",
       "       'metadata': {}},\n",
       "      {'name': 'Counter',\n",
       "       'type': 'integer',\n",
       "       'nullable': False,\n",
       "       'metadata': {}}]}}],\n",
       "  'label_column': 'VETTING_LEVEL',\n",
       "  'content_status': {'state': 'persisted'},\n",
       "  'pipeline': {'href': '/v4/pipelines/130cc296-febb-4391-8d93-95aa41ace1bd?space_id=ad49bdb4-8cce-4854-af6c-c9f7a171be40'},\n",
       "  'space': {'href': '/v4/spaces/ad49bdb4-8cce-4854-af6c-c9f7a171be40'},\n",
       "  'type': 'mllib_2.3',\n",
       "  'runtime': {'href': '/v4/runtimes/spark-mllib_2.3'}}}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.repository.store_model(model=modelRF, meta_props=model_props, training_data=train, pipeline=pipelineRF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download notebook\n",
    "\n",
    "Notebooks can be downloaded in notebook (.ipynb), Python (.py), HTML (.html), markdown (.md) or reST (.rst) format.  Use <b>File</b> > <b>Download as</b> to download the notebook in any of the formats.\n",
    "\n",
    "<img alt=\"IBM Bluemix.Get started now\" src=\"https://raw.githubusercontent.com/jpatter/LMCO/master/Lab-1/images/FileOptions.PNG\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"revert\"></a>\n",
    "## Revert to version \n",
    "Revert to the version you saved at the beginning of this lab.   There are two ways to do this.   First, select <b>File</b> > <b>Revert to Version</b> and choose the version you created at the beginning of the lab (versions are timestamped).\n",
    "<img alt=\"IBM Bluemix.Get started now\" src=\"https://raw.githubusercontent.com/jpatter/LMCO/master/Lab-1/images/FileOptions.PNG\" >\n",
    "\n",
    "The second way is to select the <b>Versions</b> icon \n",
    "<img alt=\"IBM Bluemix.Get started now\" src=\"https://raw.githubusercontent.com/jpatter/LMCO/master/Lab-1/images/versions-button.png\" ><br>\n",
    "and then select the version you wish to revert to.   You can also delete versions from here.\n",
    "<img alt=\"IBM Bluemix.Get started now\" src=\"https://raw.githubusercontent.com/jpatter/LMCO/master/Lab-1/images/Versions.PNG\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"help\"></a>\n",
    "## Even more help\n",
    "\n",
    "Select the <b>Find Resources in the Community</b> link to display a search bar, documentation hotlinks, and a link to Stack Overflow's Data Science Experience section.\n",
    "\n",
    "<img alt=\"IBM Bluemix.Get started now\" src=\"https://raw.githubusercontent.com/jpatter/LMCO/master/Lab-1/images/community-button.png\" >\n",
    "\n",
    "<img alt=\"IBM Bluemix.Get started now\" src=\"https://raw.githubusercontent.com/jpatter/LMCO/master/Lab-1/images/Community-Resources.PNG\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 with Spark",
   "language": "python3",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
